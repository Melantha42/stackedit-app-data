

# 算法效率
## 时间复杂度
事先预估算法的**时间开销T（n）**与**问题规模n**的关系
通常来说，当算法运行的问题足够大（n→$\infty$ ）时，时间复杂度遵守
- 加法规则：
 T（n）=T$_1$（n）＋T$_2$（n）=O（f(n)）＋O（g(n)）=O（max(f(n),g(n))）
【即：多项相加，只保留最高阶项，且系数变为1（高阶无穷）】
- 乘法规则：
T（n）=T$_1$（n）$×$T$_2$（n）=O（f(n)）×O（g(n)）=O（f(n)×g(n)）

>时间复杂度比较（常对冥指阶）
>**O（1）<O（log$_2$n）<O（n）<O（nlog$_2$n）<O（n$^2$）<O（n$^3$）<O（2$^n$）<O（n！）<O（n$^n$）**

## 如何计算时间复杂度
>**顺序执行的代码只会影响常数项，一般情况可以忽略**

如：int main(void)
{
①int i;
②int n;
③while(i<=n){
④i++;
⑤printf("%d",i);
}
⑥return 0;
}
语句**频度**：
①，②——1次
③——3001次
④、⑤——3000次
⑥——1次
若输入n=3000
则此代码的时间复杂度T（3000）=3n+4=O(n)
若此时在①前再添1000行代码，时间复杂度T(n)还是为O（n）

>- 如上，只需要挑选循环中的**一个基本操作**分析它的**执行次数**与n的关系即可

>- 如果有多层嵌套，只需关注最深层循环循环了几次

## Conclude 
- 如何计算时间复杂度：
①找到一个基本操作（最深层循环）
②分析该操作的执行次数x与问题规模n的关系x=f(n)
③x的数量级O（x）就是时间算法复杂度
- 三种复杂度
①最坏时间复杂度（√）
②平均时间复杂度（√）“考虑所有输入数据都等概率出现的情况”
③最好时间复杂度（×）

## 练习
int i=1;
while(i<=n){      // n为问题规模
i=i $*$ 2;  //每次循环翻倍（i=2、i=4、i=8....）
printf("i love u %d\n",i);
}
printf("i love u more than %d\n",n);

如上算法的时间复杂度设为T(n)：
设**最深**层（do while）循环的**语句频度**（总共的循环次数）为x（i=2$^x$），则由循环条件可知，循环结束时刚好满足2$^x$>n，x=log$_2$n＋1。
则T(n)=O(x)=O(log$_2$n)

## 空间复杂度

>算法代码经过转译为程序代码存入在内存中所占的位置大小

因为算法运行所需的内存空间都是固定的量与问题规模无关，所以一般不计量，算法的空间f



<!--stackedit_data:
eyJoaXN0b3J5IjpbNzU5NTM1OTksLTE3NzEyNDU4NTYsMTEzNT
UzOTkzNCwxMTEyNjA5NDUwLDExOTMzOTQwODIsLTk4NjA1MTgy
MV19
-->